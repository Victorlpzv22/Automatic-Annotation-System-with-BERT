{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "15Va5vieHPE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbb2eOB1HDf2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    sentences = df['text'].values\n",
        "    labels = df['label'].values\n",
        "    return sentences, labels\n",
        "\n",
        "def tokenize_inputs(tokenizer, sentences, labels):\n",
        "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    inputs['labels'] = torch.tensor(labels)\n",
        "    return inputs\n",
        "\n",
        "def train_model(model, optimizer, loss_fn, train_inputs, train_labels, attention_mask_train, validation_inputs, validation_labels, attention_mask_val, device, epochs):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        train_inputs = train_inputs.to(device)\n",
        "        train_labels = train_labels.to(device)\n",
        "        attention_mask_train = attention_mask_train.to(device)\n",
        "        output = model(input_ids=train_inputs, attention_mask=attention_mask_train, labels=train_labels)\n",
        "        loss = output.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            validation_inputs = validation_inputs.to(device)\n",
        "            validation_labels = validation_labels.to(device)\n",
        "            attention_mask_val = attention_mask_val.to(device)\n",
        "            output = model(input_ids=validation_inputs, attention_mask=attention_mask_val)\n",
        "            val_loss = loss_fn(output.logits, validation_labels)\n",
        "            print(f\"Epoch {epoch+1}: Train Loss = {loss.item()}, Val Loss = {val_loss.item()}\")\n",
        "\n",
        "def evaluate_model(model, test_inputs, test_labels, attention_mask_test, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_inputs = test_inputs.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "        attention_mask_test = attention_mask_test.to(device)\n",
        "        output = model(input_ids=test_inputs, attention_mask=attention_mask_test)\n",
        "        loss = loss_fn(output.logits, test_labels)\n",
        "        preds = torch.argmax(output.logits, dim=1)\n",
        "        accuracy = torch.sum(preds == test_labels) / len(test_labels)\n",
        "        print(f\"Test Loss = {loss.item()}, Test Accuracy = {accuracy.item()}\")\n",
        "        return {\"tensor([0])\": \"Animals\", \"tensor([1])\": \"Politics\", \"tensor([2])\": \"Sports\", \"tensor([3])\": \"Technology\"}.get(str(preds))\n",
        "\n",
        "def write_output(model, test_sentences, test_inputs, attention_mask_test, device, test_labels=None):\n",
        "    test_sentences = test_sentences.tolist()\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        with open(\"/output.txt\", \"w\", encoding=\"utf-8\") as w:\n",
        "            test_inputs = test_inputs.to(device)\n",
        "            attention_mask_test = attention_mask_test.to(device)\n",
        "            output = model(input_ids=test_inputs, attention_mask=attention_mask_test)\n",
        "            preds = torch.argmax(output.logits, dim=1)\n",
        "            preds_list = preds.tolist()\n",
        "            dict = {0: \"Animals\", 1: \"Politics\", 2: \"Sports\", 3: \"Technology\"}\n",
        "            for i in range(len(test_sentences)):\n",
        "                w.write(f\"Sentence: {test_sentences[i]}, Category: {dict.get(preds_list[i])}\\n\")\n",
        "            if test_labels != None:\n",
        "                acc = torch.sum(preds == test_labels) / len(test_labels)\n",
        "                w.write(f\"\\n\\nAccuracy = {acc.item()}\")\n",
        "\n",
        "def sentence_category(model, device):\n",
        "    sentence = [str(input(\"Type the sentence you want to test the model: \"))]\n",
        "    label = [int(input(\"Type the label of the previous sentence [0 (Animals), 1 (Politics), 2 (Sports), 3 (Technology)]: \"))]\n",
        "    test = tokenize_inputs(tokenizer, sentence, label)\n",
        "    test_inputs, test_labels = test['input_ids'], test['labels']\n",
        "    attention_mask_test = test['attention_mask']\n",
        "    print(f\"Sentence: {sentence[0]}, Category: {evaluate_model(model, test_inputs, test_labels, attention_mask_test, device)}\")"
      ],
      "metadata": {
        "id": "pqPI2SlNHFz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizar los inputs y agregar las etiquetas\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "gPKBCon3Sk94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los datos de entrenamiento\n",
        "train_sentences, train_labels = load_data(\"/train.csv\")\n",
        "train = tokenize_inputs(tokenizer, train_sentences.tolist(), train_labels)\n",
        "train_inputs, train_labels = train['input_ids'], train['labels']\n",
        "attention_mask_train = train['attention_mask']"
      ],
      "metadata": {
        "id": "zDmjBP9NSOr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los datos de validación\n",
        "validate_sentences, validate_labels = load_data(\"/validate.csv\")\n",
        "validation = tokenize_inputs(tokenizer, validate_sentences.tolist(), validate_labels)\n",
        "validation_inputs, validation_labels = validation['input_ids'], validation['labels']\n",
        "attention_mask_val = validation['attention_mask']"
      ],
      "metadata": {
        "id": "pQVEB2yWSOet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los datos de test\n",
        "test_sentences, test_labels = load_data(\"/test.csv\")\n",
        "test = tokenize_inputs(tokenizer, test_sentences.tolist(), test_labels)\n",
        "test_inputs, test_labels = test['input_ids'], test['labels']\n",
        "attention_mask_test = test['attention_mask']"
      ],
      "metadata": {
        "id": "lcnkV9AkJvVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el modelo, la función de pérdida y el optimizador\n",
        "num_labels = len(set(train_labels))\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, output_hidden_states=True)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "zPRSYNPUJ57E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "epochs = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_model(model, optimizer, loss_fn, train_inputs, train_labels, attention_mask_train, validation_inputs, validation_labels, attention_mask_val, device, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR4L0UnLLcYA",
        "outputId": "a1c4f421-950f-4b10-de57-bd2771e27b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4.690629482269287, Val Loss = 4.5714592933654785\n",
            "Epoch 2: Train Loss = 4.573722839355469, Val Loss = 4.44631814956665\n",
            "Epoch 3: Train Loss = 4.4427971839904785, Val Loss = 4.291373252868652\n",
            "Epoch 4: Train Loss = 4.303201198577881, Val Loss = 4.098897933959961\n",
            "Epoch 5: Train Loss = 4.122618198394775, Val Loss = 3.9237029552459717\n",
            "Epoch 6: Train Loss = 3.9489762783050537, Val Loss = 3.783336639404297\n",
            "Epoch 7: Train Loss = 3.8065996170043945, Val Loss = 3.6169421672821045\n",
            "Epoch 8: Train Loss = 3.6368775367736816, Val Loss = 3.4404549598693848\n",
            "Epoch 9: Train Loss = 3.4653029441833496, Val Loss = 3.2829253673553467\n",
            "Epoch 10: Train Loss = 3.30116605758667, Val Loss = 3.1277737617492676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "evaluate_model(model, test_inputs, test_labels, attention_mask_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0TN4HC-Yor1",
        "outputId": "0c4af941-9b60-417f-c74f-b09dd7aec85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss = 3.1580255031585693, Test Accuracy = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribir una oración y label por teclado. Dice si el modelo ha acertado o no y el label que ha asignado.\n",
        "sentence_category(model, device)    "
      ],
      "metadata": {
        "id": "koDxIVEiIX8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asigna una label a cada oración de test y lo escribe en un fichero de texto. Si se añaden los labels de test, escribe también la accuracy del modelo.\n",
        "write_output(model, test_sentences, test_inputs, attention_mask_test, device, test_labels)"
      ],
      "metadata": {
        "id": "Xp-QsY7JXB4c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}